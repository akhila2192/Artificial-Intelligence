{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a63ba1f-3dee-42ea-a66b-c00d9ba829ec",
   "metadata": {},
   "source": [
    "https://thecleverprogrammer.com/2021/09/13/twitter-sentiment-analysis-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8770c2af-f951-49ca-86ba-f94509a661ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b03372e-ab5e-456b-93cf-b9f658b69c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "5           5      3            1                   2        0      1   \n",
      "6           6      3            0                   3        0      1   \n",
      "7           7      3            0                   3        0      1   \n",
      "8           8      3            0                   3        0      1   \n",
      "9           9      3            1                   2        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
      "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
      "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
      "8  \" &amp; you might not get ya bitch back &amp; ...  \n",
      "9  \" @rhythmixx_ :hobbies include: fighting Maria...  \n"
     ]
    }
   ],
   "source": [
    "data =pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/twitter.csv\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3de6b77-9e81-4576-a049-9e03255c58bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akhil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebaa5301-7d87-4ecc-9490-b4e9ace520ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ours', 'a', 'through', 'of', \"it's\", 'below', 'doing', 're', 'some', 'yourselves', 'during', 'been', 'ain', 'our', 'out', 'nor', 't', 'his', 'am', 'are', 'were', 'such', 'ourselves', 'both', \"aren't\", 'its', 'me', 'yours', 'isn', \"wasn't\", 'from', 'hadn', 'does', 'haven', 'those', 'not', \"you'll\", 'i', 'it', \"mightn't\", \"should've\", 'don', 'and', \"you've\", 'theirs', 'against', 'under', \"wouldn't\", 'here', 'more', 's', 'was', 'll', 'didn', 'down', 'couldn', 'having', 'my', 'or', \"couldn't\", 'had', 'over', 'ma', 'if', 'these', 'is', 'themselves', 'the', 'before', 'y', 'all', 'who', \"won't\", \"don't\", 'itself', 'no', \"shouldn't\", 'how', 'between', 'only', 'just', 'won', 'we', 'an', \"she's\", 'further', 'each', 'now', 'them', 'until', 'in', 'at', \"you'd\", 'other', 'will', \"needn't\", 'this', \"shan't\", 'did', 'needn', 'he', 'into', 'm', 'that', 'but', 'mightn', 'most', 'you', 'by', 'being', \"mustn't\", 'while', 'to', 'very', 'd', \"doesn't\", \"haven't\", 'aren', 'hers', 'when', 'there', \"weren't\", 'whom', 'myself', \"that'll\", 'should', 'weren', \"you're\", 'once', 'about', 'wasn', 'above', \"didn't\", \"isn't\", 'wouldn', \"hasn't\", 'than', 'has', 'doesn', 'which', 'same', 'shan', 'for', \"hadn't\", 'on', 'what', 'yourself', 'be', 've', 'so', 'too', 'they', 'him', 'after', 'her', 'can', 'why', 'with', 'off', 'again', 'have', 'she', 'hasn', 'then', 'up', 'do', 'their', 'where', 'o', 'your', 'shouldn', 'because', 'herself', 'as', 'any', 'mustn', 'few', 'himself', 'own'}\n"
     ]
    }
   ],
   "source": [
    "stemmer=nltk.SnowballStemmer('english')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b95982f1-4cc6-44c1-a460-76a889fbc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akhil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK stopwords are downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stopwords and stemmer\n",
    "stopword = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean(text):\n",
    "    # Ensure the text is a string and convert it to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove text inside square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    \n",
    "    # Remove words containing digits\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    \n",
    "    # Rejoin words after removing stopwords\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Apply stemming to each word\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'tweet' column\n",
    "data['tweet'] = data['tweet'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44306712-0db1-4c72-8b12-b4fac27a91cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rt mayasolov woman shouldnt complain clean hou...\n",
       "1     rt boy dat coldtyga dwn bad cuffin dat hoe place\n",
       "2    rt urkindofbrand dawg rt ever fuck bitch start...\n",
       "3                rt cganderson vivaba look like tranni\n",
       "4    rt shenikarobert shit hear might true might fa...\n",
       "5    tmadisonx shit blow meclaim faith somebodi sti...\n",
       "6    brighterday sit hate anoth bitch got much shit go\n",
       "7                 cau im tire big bitch come us skinni\n",
       "8                      amp might get ya bitch back amp\n",
       "9             rhythmixx hobbi includ fight mariambitch\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244c7571-9c93-43fe-ac59-36799df0bd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\akhil\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating sentiment score and assiging the labels\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "027078cb-9159-46a8-8596-a7d4a61b9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments=SentimentIntensityAnalyzer()\n",
    "data['Positive']=[sentiments.polarity_scores(i)['pos'] for i in data['tweet']]\n",
    "data['Negative']=[sentiments.polarity_scores(i)['neg'] for i in data['tweet']]\n",
    "data['Neutral']=[sentiments.polarity_scores(i)['neu'] for i in  data['tweet']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c0203f-9ecd-4cd2-86d5-f41c60bee764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt mayasolov woman shouldnt complain clean hou...</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt boy dat coldtyga dwn bad cuffin dat hoe place</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt urkindofbrand dawg rt ever fuck bitch start...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt cganderson vivaba look like tranni</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt shenikarobert shit hear might true might fa...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  Positive  Negative  \\\n",
       "0  rt mayasolov woman shouldnt complain clean hou...     0.147     0.157   \n",
       "1   rt boy dat coldtyga dwn bad cuffin dat hoe place     0.000     0.280   \n",
       "2  rt urkindofbrand dawg rt ever fuck bitch start...     0.000     0.577   \n",
       "3              rt cganderson vivaba look like tranni     0.333     0.000   \n",
       "4  rt shenikarobert shit hear might true might fa...     0.154     0.407   \n",
       "\n",
       "   Neutral  \n",
       "0    0.696  \n",
       "1    0.720  \n",
       "2    0.423  \n",
       "3    0.667  \n",
       "4    0.440  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[['tweet','Positive','Negative','Neutral']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5eefcfa-cd65-4e0b-af20-05dfbffef907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "x=sum(data['Positive'])\n",
    "y=sum(data['Negative'])\n",
    "z=sum(data['Neutral'])\n",
    "\n",
    "def sentiment_score(a,b,c):\n",
    "    if (a>b) and (a>c):\n",
    "        print('Positive')\n",
    "    elif (b>a) and (b>c):\n",
    "        print('Negative')\n",
    "    else:\n",
    "        print('Neutral')\n",
    "\n",
    "sentiment_score(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c72cd-401e-4a33-bb36-64ee11d9e20e",
   "metadata": {},
   "source": [
    "Most of the tweets are neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c770aa84-ad44-4d43-8a96-305c8c1ee308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867.841\n",
      "7225.518\n",
      "14684.634\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c385cf-c229-4bbd-9b62-cb675f36c563",
   "metadata": {},
   "source": [
    "total of neutral is higher than positive and negative.\n",
    "negative is higher than positive so we can say most of the opinions are negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25a64a-0c1b-44bb-a0e8-76d7b12032c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
